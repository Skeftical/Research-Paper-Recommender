Finding and Analyzing Database User Sessions
Qingsong Yao, Aijun An, and Xiangji Huang
Department of Computer Science, York University, Toronto M3J 1P3 Canada
{qingsong, aan}@cs.yorku.ca, jhuang@yorku.ca

Abstract. A database user session is a sequence of queries issued by a user (or
an application) to achieve a certain task. Analysis of task-oriented database user
sessions provides useful insight into the query behavior of database users. In this
paper, we describe novel algorithms for identifying sessions from database traces
and for grouping the sessions different classes. We also present experimental
results.

1

Introduction

A database user session is a sequence of queries issued by a user (or an application)
to achieve a certain task. It consists of one or more database transactions, which are in
turn a sequence of operations performed as a logical unit of work. Analysis of sessions
allows us to discover high-level patterns that stem from the structure of the task the user
is solving. The discovered patterns can be used to predict incoming user queries based
on the queries that the user has already issued [1, 2, 3] and to redesign and rewrite the
queries within a user session to achieve a better performance [4, 5].
In this paper, we are interested in identifying and clustering database user sessions
from database workloads. We use a language modeling based algorithm to identify
database sessions, and a distance-based clustering algorithm is proposed to group the
user sessions into different session classes. Our contributions in this paper are summarized as follows. (1) We use a language statistical modeling based algorithm to identify
database sessions. Three types of learning methods, namely, supervised, semi-supervised
and unsupervised learning, are introduced to learn language models. These learning
methods are designed to suit the different characteristics of real log data sets. (2) We
propose a distance-based session clustering algorithm to cluster session instances. The
distance between two session instances is measured according to three similarity scores:
coefficient score, alignment score and neighborhood score. This approach considers not
only the local similarity between sessions (coefficient score, alignment score), but also
the global similarity (neighborhood score).
The rest of the paper is organized as follows. Related work is discussed in Section
2. We describe the language modeling based session identification algorithm in Section
3. In Section 4, a distance-based session clustering algorithm is proposed. We give
experimental results in Section 5. Finally we conclude the paper in Section 6.


This work is supported by research grants from Communications and Information Technology Ontario (CITO) and the Natural Sciences and Engineering Research Council of Canada
(NSERC).

L. Zhou, B.C. Ooi, and X. Meng (Eds.): DASFAA 2005, LNCS 3453, pp. 851–862, 2005.
c Springer-Verlag Berlin Heidelberg 2005


852

2

Q. Yao, A. An, and X. Huang

Related Work

Finding database user behaviors is a subject of workload characterization. There is a
large variety of techniques used for workload characterization. Functionally, the workload characterization can be classified into two categories: static analysis and dynamic
analysis. Static techniques explore the intrinsic characteristics of the workload, such as
the static parameters related to hardware and software resource consumptions and the
correlation between workload parameters, which do not change over time. On the other
hand, dynamic techniques, such as neural network based prediction, Markov models,
user behavior graphs, customer behavior model graph and regression methods, focus
on analyzing the behavior of the workload and the way it fluctuates over time. These
techniques usually analyze the historical data of the workload and aid to forecasting
its behavior in the future. Surveys on workload characterization techniques on different
computer systems, such as file servers and database systems, can be found in [6, 7]. In
this paper, we focus on analyzing database user behaviors within the user session level,
i.e, the queries submitted by a user within a user session.
The most commonly used session identification method is called timeout, in which
a user session is defined as a sequence of requests from the same user such that no two
consecutive requests are separated by an interval more than a predefined threshold. This
session identification method suffers from the problem that it is difficult to set the time
threshold. According to [8], timeout method is the only method provided by database
vendors to keep track of sessions for electronic library database products. They reported
that timeout values can vary widely between vendors, ranging from 7 to 30 minutes
on average. Recently, an n-gram statistical language modeling based session detection
method has been proposed in [9]. The method has been demonstrated to be more effective
than the timeout and two other methods in discovering interesting association rules in a
Web mining domain. However, some open issues, such as how to select parameters and
how to measure the session identification results, are still unsolved. A review of N-gram
modeling can be found in [10].
Data clustering is a subject of active research in several fields such as statistics
analysis, pattern recognition, and machine learning. A review of clustering techniques is
given in [11]. A survey on data clustering algorithms can be found in [12]. The session
clustering algorithm presented in the paper is based on the idea of Jaccard Coefficient
measurement [13], sequence alignment [14], and common neighbors between sessions
[15]. Similar algorithms can be found in [15, 16, 17].

3

Database User Session Identification

First, we briefly discuss the procedure of finding and clustering user sessions from
database workloads. The database workload contains many database connections, and
each connection contains a sequence of queries. We assume that queries within a user
session have the same connection id, and there is no interleave between two sessions of
a connection. Thus, the query sequence of a connection corresponds to a sequence of
user sessions. Language modeling provides a simple, natural approach to segmenting
template sequences. Since the submitted SQL queries usually have certain format, they

Finding and Analyzing Database User Sessions

853

can be classified into different query templates (step 1). In particular, we replace each
data value embedded in a SQL query with a wildcard character ’%’, and obtain a query
template. The query template represents a set of queries that have the similar format. By
replacing a submitted SQL statement with the corresponding query template, we obtain
a set of query template sequences, referred to as template sequences (step 2 and 3),
each for one database connection. The template sequences are the input of the session
identification algorithm. For example, the session instance shown in Table 1 corresponds
to a template sequence: 30-09-10-20-47-49. Learning from session instances can help
us to predict, prefetch and rewrite the queries in the session (see [2] for details).
Table 1. An instance of schedule display session procedure
Label Statement
30
09
10
20
47
49

3.1

select authority from employee where employee id =’1025’
select count(*) as num from customer where cust num = ’1074’
select card name from customer t1,member card t2 where 1.cust num = ’1074’ and
t1.card id = t2.card id
select contact last,contact first from customer where cust num = ’1074’
select t1.branch ,t2.* from record t1, treatment t2 where t1.contract no = t2.contract no
and t1.cust id =’1074’ and check in date = ’2002/03/04’ and t1.branch =’scar’
select top 10 contract no from treatment schedule where cust id = ’1074’ order by
checkin date desc

N-Gram Statistical Language Modeling

In this section, we present a session detection method based on language models. The
method does not rely on any time intervals when identifying session boundaries. Instead,
it uses an information theoretic approach to identifying session boundaries dynamically
by measuring the change of information in the sequence of requests. The method was
originally proposed for detecting session boundaries in Web logs [9].
Statistical language modeling was originally used in speech recognition, where the
goal is to predict the probability of natural word sequences. The most successful statistical language model is the n-gram language model. In n-gram language modeling, it is
assumed that the probability of a word only depends on its at most previous n-1 words.
Thus, given a word sequence, s = w1 w2 ...wN , its probability can be written as:
P (s) = P (w1 )..P (wN |w1 ..wN −1 ) =

N


P (wi |w1 ..wi−1 ) =

i=1

N


P (wi |wi−n+1 ..wi−1 )

i=1

A statistical language model, then, is a specific choice of conditional probabilities for
all possible n-grams: P (wi |wi−n+1 ...wi−1 ). The quality of a given statistical language
model can be measured by its empirical entropy on a given word sequence s , where the
empirical entropy is defined as
Entropy(s) = −

1
log2 P (s)
N

854

Q. Yao, A. An, and X. Huang

That is, we would like the language model to place high probability on natural test
sequences, and hence obtain a small value of empirical entropy.
In database applications, queries are issued sequentially in a particular order, similar
to the word sequences that occur in a natural language. If we consider each query as a
basic unit, like a word or character in natural language, we can then attempt to estimate
the probability of query sequences using the same language modeling tools described
above. Imagine a set of queries for a task/session that are frequently issued one after
another. In this case, the entropy of the sequence is low. However, when a new query is
observed in the sequence that is not relevant to the original task (but in fact indicates a
shift to a new task), the introduction of this new query causes an increase in the entropy
of the sequence because it is rarely issued after the preceding sequence of queries. If
the change in entropy passes a threshold, a session boundary could be placed before
the new query. In other words, the uncertainty (which is measured by entropy) within
a session should be roughly constant, allowing for a fixed level of variability within a
topic. However, whenever the entropy increases beyond a threshold, this presents a clear
signal that the user’s activity has changed to another topic. Thus, we should set a session
boundary at the place where the entropy changes. The change in entropy is measured by
the relative change in entropy values, defined as
Entropy(s1 ) − Entropy(s0 )
Entropy(s0 )
where s0 is a sequence of requests and s1 contains s0 plus the next request following s0
in the test data sequence. Based on this definition, a threshold value of 0.20 means that
if the change in entropy is over 20%, there is a boundary at the end of s0 .
Fig. 1 shows the entropy evolution of a query sequence within a database connection
from our OLTP application, where the X-axis is the sequence represented by query
template ids, Y-axis is the entropy of the sequence from the first query to the current
query, and the threw curves are based on the n-gram models trained in the unsupervised,
supervised and semi-supervised modes (explained in next section), respectively. As one
can see, the entropy changes radically at some points, although it remains stable in other
places. This figure gives an intuition how entropy could be used for session boundary
detection.
3.2

Training Data and Learning Methods

The probabilities in an n-gram model come from the data it is trained on. The training
data need to be carefully designed. If the training data is too specific to one task, the
probabilities may be too narrow and do not generalize well to other tasks. If the training
data is too general or too small, the probabilities may not reflect the task or the domain
efficiently. A good training data should contain enough information about the observed
application or user, i.e., the training data should reflect the dynamic behavior of the
observed application or the users.
There are three kinds of training data, separated training data, un-separated training
data and partially separated training data. In separated training data, sessions have been
identified and thus the training data consists of a set of sessions. We refer to the n-gram
learning method that is based on the separated training data as supervised learning

Finding and Analyzing Database User Sessions

855

method. In some situations, it is very difficult, if not impossible, to obtain a separated
training data set. In this case, we can estimate request frequencies based on the unseparated data sequence, and the corresponding n-gram model contains both the intersession and the intra-session request frequencies. The corresponding learning method
is called the unsupervised session detection method. The unsupervised learning is more
sensitive to the selection of parameters, such as the entropy threshold and the n-gram
order (as shown in Fig. 1). In a third type of situation, the training data are partially
separated by the boundary points such as use login/logout. In this case, we can build an
n-gram model by estimating the probabilities based on the partially separated training
data. We refer to this method as semi-supervised learning method.
5

4.5

Unsupervised
Supervised
Semi−Supervised

1.4

Value

1.2

F-Measure

entropy

4

3.5

1

3

0.8

2.5

Cross-Entropy

0.6

2

0.4
1.5

0.2

1

Threshold(%)

Fig. 1. Entropy evolution in one data set

3.3

0
20

0
12

90

70

50

7 50 37 24 30 54 54 54 54 54 45 20 43 43 43 43 43 43 43 43 43 43 45 20 43 43 43 43 43 43
sequence

30

0

0

10

0

0.5

Fig. 2. Correlation between F-measure and crossentropy

Performance Measurement Metrics

After an n-gram model is built over the training data, it can be used to divide an unseparated template sequence into sessions. Performance measures are needed to evaluate the
accuracy of the session detection. In this section, we propose to use two performance measures and discuss their correlations. The first measure is referred to as F-measure, which
has been used in information retrieval to measure the retrieval performance. Suppose we
know the true session boundaries in the test sequence, then F-measure is defined as
F-Measure =

2 ∗ precision ∗ recall
,
precision + recall

where precision is defined as the ratio of the number of correctly detected session boundaries to the total estimated boundaries, and the recall is the hit-rate, that is, the ratio of
the number of correctly detected true session boundaries to the total number of true
boundaries, A higher F-measure value means a better overall performance.
The second measure is called cross entropy. Given a set of estimated sessions T =
{t1 , ..., tm }, detected by using a model P (wi |wi−n+1 ...wi−1 ), the cross entropy of T is
define as:

(|ti | × entropy(ti ))

Hp (T ) = i
i |ti |

856

Q. Yao, A. An, and X. Huang

The cross-entropy value can be interpreted as the average number of bits needed to encode
T by using the compression algorithm associated with model P (wi |wi−n+1 ...wi−1 ). A
smaller cross-entry value means a better compression algorithm, and a better session
separating model as well. Fig. 2 shows the inverse correlation between F-measure and
cross entropy. It depicts how the performance of the n-gram based session identification
method, measured by both performance measures, changes with the value of the entropy
threshold on a data set used in our application. An advantage of using cross entropy to
measure the performance of an n-gram model for session detection is that we do not
need to know the true session boundaries in test data to calculate the cross entropy. This
feature makes it possible to make use of cross entropy as a performance measure on
the test data set for adjusting the parameters of an n-gram model. However, the n-gram
model should be trained in the supervised mode (i.e. on the separated data set) in order
for cross entropy to be a reliable performance measure on test data.
3.4

Parameter Selection

There are two parameters in the language modeling based session detection method.
One is the order of the n-gram model, which is n. The other is the entropy change
threshold used in segmenting the test sequence. Threshold selection is a critical task of
the language modeling based session boundary detection method. If the threshold is too
large, many session boundaries are missed and the recall of the detection is low. On
the other hand, a small threshold causes many non-boundary events to be mistreated as
session boundaries, which results in low precisions. In both cases, the performance in
term of F-Measure is low. To see how threshold selection is important, we compared
the performances of the n-gram method based on different threshold values. The result
is shown in Fig. 3. We can observe that the performance of an n-gram model greatly
depends on the threshold value.
To achieve good performance, we propose an automatic method for choosing a
threshold value for our language model session detection method. Suppose that the test
data sequence has m sessions and N events. After we estimate the entropy value of
each sequence in the test data, we can calculate and sort the relative entropy difference
values in decreasing order. If our language model can find all m-1 session boundaries
correctly, then the corresponding relative entropy difference values will occupy the first
m-1 positions in the sorted list. Thus, the mth value in the sorted list is the estimated
threshold value. In practice, we may not know the actual value of m. However, if we
know the average session length (avgLen), we can estimate m to be N/avgLen and
thus choose the (N/avgLen)th value in the sorted list as the threshold value. For supervised learning, we can estimate the average session length from the training data. For
unsupervised or semi-supervised learning, we can use the development set to estimate
the average session length. Also, for different n-gram orders, the estimated threshold
values are different.
Fig. 4 illustrates how the performance of an n-gram method changes with the order
of the model on one of our test data sets. Since different data sets may achieve the
best performance at different order values, an automatic method for order selection is
necessary. We propose the following method to select the best n-gram order for a data
set. For supervised learning, we train a set of n-gram models with different n values,

Finding and Analyzing Database User Sessions
0.9

0.9

F-Measure
2-gram

0.8

3-gram
4-gram

0.7

5-gram

0.6

6-gram

857

F-Measure

0.8
0.7
0.6

7-gram

0.5

0.4

0.3

0.3

0.2

0.2

Threshold(%)

0.1

N-Gam Order
80
10
0

60

40

20

18

16

14

12

8
10

6

4

0.1
2

0

Threshold:
0.10
0.12
0.14
0.16
0.18

0.5

0.4

Fig. 3. Performance change with different
threshold values

1

2

3

4

5

6

7

8

9

10

Fig. 4. Performance change with different n–
gram orders

say from 2 to 8, on the training data set. We then test each model on the unseparated test
data sequence with an entropy threshold selected using the automatic threshold selection
method. The performance of each model on the test sequence is measured in terms of
cross entropy. The model with the smallest cross entropy is selected. Cross entropy,
instead of F-measure, is used as the performance measure in this process because it
can be calculated without knowing the true boundaries in the test data sequence. For
unsupervised or semi-supervised learning, a set of n-gram models with different n values
is trained on the unseparated or partially separated training data. Then each model is
tested on the development set. The performance of each model on the development
set is measured by F-measure. The model with the highest F-measure is chosen. Note
that we cannot use the test data sequence and cross entropy to test the models as in
supervised learning because the models are trained on the unseparated data and thus the
unseparated test data sequence will have the smallest cross entropy. Using F-measure
on the development set is more reliable in this situation.

4
4.1

Database Session Clustering
Session Similarity Scores and Distance Function

Given a set of database session instances, s = s1 , s2 , ..., sn , where each session instance
contains a sequence of requests, i.e., si =< ri1 ri2 ....rim >, our task is to group the
session instances into meaningful session classes. The idea of our distance-based session
clustering algorithm is described as follows. We first consider each session instance as a
session class, and calculate the distance between them. Then, session groups are merged
according to their intra-group distances, and group distances are updated correspondingly. The clustering procedure stops when all intra-group distances are more than a
pre-defined distance threshold β1 . The distance between two session instances si and sj
is defined as:
1.0 − α1 × csim(si , sj ) − α2 × asim(si , sj ) − α3 × nsim(si , sj ),

(1)

858

Q. Yao, A. An, and X. Huang

where csim, asim, nsim are the coefficient score, the alignment score, and the neighborhood score, respectively. α1 , α2 , and α3 are the distance parameters, the sum of which
is 1.0. The coefficient score csim(si , sj ), for two session instances si and sj , is defined
|s ∩s |
as |sii ∪sjj | , where |si ∩ sj | is the number of the requests appearing in both si and sj ,
and |si ∪ sj | is the total number of requests appearing in si or sj . The coefficient score
is based on the Jaccard Coefficient measure [13] that treats sessions as un-ordered sets.
The similarity between two sessions in this measure is defined as the fraction of common
requests.
We observe that if two session instances belong to the same session class, they are very
likely to have similar template sequence. Therefore, we propose another scoring schema
based on the idea of sequence alignment. In sequence alignment, two or more strings are
aligned together in order to get the highest number of matching characters. Gaps may
be inserted into a string in order to shift the remaining characters into better matches.
In this paper, we use the Needleman-Wunsch algorithm [14], a well-known sequence
alignment algorithm, to align two sessions, and assign a score based on aligned session
sequences, referred as the alignment score. We assume that the sessions are controlled
by certain programming codes. The codes may contain branches (such as if/else and
switch-case statements) or cycles (such as for-loop and do-while statements) that may
cause the requests to be executed repeatedly. The branches and cycles can be observed
from the aligned session instances. For example, given two session instances, ABCDD
and ABED, the aligned sequences are ABCDD
ABED− . We observe that the sequences contain
two matches (A and B), one branch (C/E) and one cycle (DD/D). We assign each
match with a score of 2, each branch with a score of 1, and each cycle with a score of
1. To normalize the alignment score, we divide the assigned value by the length of the
aligned sessions. The length is defined as 2 * (num. of matches + num. of branches +
num. of cycles). Thus, the final alignment score of the two sequences is 6/8 = 0.75. The
hidden logic/code in the real application may be complex than in the above example,
but the principle is still applicable.
In some situations, two sessions are in the same session class but their distance is
not so “near". Thus, simply applying the two similarity scores as the distance metric
is not enough. It is necessary to take global similarity into consideration. We call two
session instances si and sj ”neighbors" if the local-distance between them is within a
pre-defined threshold β2 . The local-distance can be estimated by using the combination
of the coefficient score and the alignment score by assuming that the neighborhood score
is 0. Thus, each session has a set of neighbors. Each session pair, < si , sj >, has a value,
nsim(si , sj ), which is the faction of common neighbors between them. This score is
called the neighborhood score.
4.2

Distance-Based Session Clustering Algorithm

The step of session distance computing has a high space and time complexity. For example, given a data set that contains k session instances, k 2 scores need to be calculated.
Meanwhile, to align two sequences with length m and n, the Needleman-Wunsch algorithm requires O((m + 1) × (n + 1)) space to store the matrix, and O(m × n) time
to compute the matrix and then O(m + n) time to find an optimal path. In this section,
several strategies are proposed to solve the problem.

Finding and Analyzing Database User Sessions

859

First, we observe that there are some repeated session instances in the data set, which
have the same template sequences. These session instances are in the same session class.
Thus, we can represent repeated sessions by using a single session si associated with
the occurrence frequency, f req(si ).
The next strategy is concerned with session class representation. It is implausible to
use all session instances to represent a session class. Thus, we use two sets, the request
set, rset(gj ), and the session set, sset(gj ) together, to represent a session class gi .
rset(gj ) contains all distinct requests appeared in gj , and sset(gj ) contains a set of the
representative session instances. We observe that if session group gi and gj are likely to
be merged, they should have a large portion of common requests. Thus, we use formula
|rset(gi )∩rset(gj )|
|rset(gi )∪rset(gj )| > β3 to pre-eliminate un-related groups when merging them. The sset
is used to compute the distance between session groups. Frequent session instances are
usually in sset. The distance between two session groups is then defined as:


sm ∈sset(gi )
sn ∈sset(gj ) distance(sm , sn ) × f req(sm ) × f req(sn )


(2)
sm ∈sset(gi )
sn ∈sset(gj ) f req(sm ) × f req(sn )
When two session groups are merged, the sset and rest are changed correspondingly.
Data sampling is used to reduce computing complexity and space requirement. Finally session classes with small number of session instances (the number is smaller than
a predefined threshold) are treated as noise and are removed.

5

Experimental Results

To test our ideas in the project, we use a clinic OLTP application as a test bed. The clinic
is a private physiotherapy clinic located in Toronto. It has five branches across the city. It
provides services such as joint and spinal manipulation and mobilization, post-operative
rehabilitation, personal exercise programs and exercise classes, massage and acupuncture. In each day, the client applications installed in the branches make connections to
the center database server, which is Microsoft SQL Server 7.0. In each connection, a
user may perform one or more tasks, such as checking in patients, making appointments,
displaying treatment schedules, explaining treatment procedures and selling products.
The database trace log (400M bytes) contains 81,417 events belonging to 9 different applications, such as front-end sales, daily report, monthly report, data backup, and system
administration. Our target application is the front-end sales application. After preprocessing the trace log, we obtain 7,244 SQL queries, 18 database connection instances of
the front-end sales application. The queries are classified into 190 query templates, and
18 template sequences are obtained.
5.1

Results for Session Identification Algorithm

We randomly selected four test data sets from the collected data set, referred to as
D1 , D2 , D3 , and D4 . Each test data set corresponds to one database connection. For
supervised learning, the four test data sets are taken out from the training data. For
unsupervised or semi-supervised learning, we use the whole data set as the training data

860

Q. Yao, A. An, and X. Huang

to calculate the probabilities in the n-gram model, and use D1 as the development set
to tune parameters. The learned model are tested on D2 , D3 , and D4 . For the semisupervised method, some boundary “words" are used to partially separate the training
data sequences. In our application, the boundary words are user sign-in/sign-out and
user authority checking. However, in our data set, not all the sessions begin or end with
a boundary word.
For the timeout method, we conducted experiments with a number of timeout thresholds, ranging from 0.2 second to 30 minutes. The results of these timeout methods in
terms of F-Measure are shown in Fig. 5. The results show that the best performance in
term of F-measure is around 70%. The performance of the timeout method obviously
depends on the timeout threshold. Different applications may have different best timeout
thresholds. In our particular application, a threshold value between 3 to 10 seconds leads
to the best performance for the timeout method.
0.9

Threshold (s)

F-Measure

0.2
15

0.8

0.5
20

1
60

2
120

3
300

0.95
5
600

8
1200

10
1800

0.7

0.85

0.6

0.8

0.5

TimeOut
F-Measure

Unsupervised
Supervised

0.9

Semi-Supervised

0.75

0.4

0.7

0.3

0.65

0.2

0.6
0.1

0.55
0

D1

D2

D3

D4 Data Set 0.5
D1

Fig. 5. Comparison of timeout thresholds

D2

D3

D4 Data Set

Fig. 6. Comparison of All the Methods

In Fig. 6, we compare all the methods in terms of F-measure. The results for the
unsupervised, supervised and semi-supervised methods are the results from the automatic
parameter selection method. The result for the timeout method on a data set is the best
timeout result on that data set. We can observe from the figure that the supervised learning
method achieves the best results on all the test data sets; semi-supervised learning method
is comparable to the unsupervised method on the first three data sets but is significantly
better than the unsupervised method on data set D4 ; all the three n-gram methods are
significantly better than the best timeout method (except on D4 the performance of the
unsupervised method is slightly worse than that of the best timeout method). In general,
we can say that, using the automatic parameter selection method, the n-gram based
session identification method is significantly better than the timeout method, which has
been the only method for database session identification.
5.2

Results for Session Clustering Algorithm

We implement our session clustering algorithm in Java. The performance of the session
clustering algorithm depends on the selection of distance thresholds and distance param-

Finding and Analyzing Database User Sessions

861

eters. If the distance thresholds are too small, many session classes are generated. But
if they are too large, sessions that belong to different classes may be merged. Among
the three distance thresholds, β1 is the most important since the two other values are
related to it, and can be derived from it. The selection of threshold values depends on the
application. Small threshold values can be used for applications in which the difference
between session classes is significant, i.e., the distance between them is “far"; otherwise,
large threshold values are used since they can discriminate the trivial difference between
session classes. The selection of distance parameters is also important. The parameters
can be viewed as the weight of the three similarity scores. Different applications may
require different parameter values, and adjustment of these parameters accordingly is
necessary.
In the experiments, we choose 721 session instances that belong to 4 template sequences as the input of clustering algorithm. We first test the number of clusters generated
with different distance parameters in the sampling step. We set the neighborhood distance parameter as 0.3, and the coefficient parameter is dynamically changed from 0.0
to 0.7, and the alignment parameter is changed correspondingly. The result is shown in
Fig. 7. The figure shows that more clusters are generated when the coefficient parameter
is large, and fewer clusters are generated when the alignment parameter is large.
50
Num. of Clusters

45

threshold:
0.4
0.6

0.2
0.5
0.8

90
80

40

70

35

num. clusters before pruning
num. clusters after pruning

60

30

50

25

40

20

30

15

20

10

10
threshold value

5

Coefficient weight

0
0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70

Fig. 7. Number of clusters vs. various
distance parameter values

0
0

5
.0

1
0.

0

5
.1

2
0.

0

5
.2

3
0.

0

5
.3

4
0.

0

5
.4

5
0.

0

5
.5

0

5
.6

7
0.

0.

75

0.

8

0.

9

0.

95

Fig. 8. Number of clusters vs. various threshold
values (pruning threshold =10)

Next, we use 0.4,0.3,0.3 as distance parameters in the first step, and 0.5,0.5, 0.0 in
the second step, and evaluate the performance under different threshold values. Since
the values of β2 and β3 are correlated with β1 , we mainly change the value of β1 , and the
other threshold values are changed correspondingly. The result is shown in Fig. 8. From
the figure, we observe that the number of clusters increases when the threshold value
increases. However, the increasing rate after pruning is lower than that before pruning.

6

Conclusion

In this paper, we have discussed our approach to identifying and grouping database user
sessions. The results from our approach can be used to tune the database system and

862

Q. Yao, A. An, and X. Huang

predict incoming queries based on the queries already submitted, which can be used
to improve the database performance by effective query prefetching, query rewriting
and cache replacement. The work presented in the paper has a broader impact on the
database and data mining fields. Although the data set used in the paper is based on a
clinic application, the idea presented in the paper can be used in other database-based
applications, such as the ERP/CRM applications that may contain hundreds or even
thousands different types of sessions. It can also be used on Web log analysis and DNA
sequence analysis.

References
1. Sapia, C.: PROMISE: Predicting query behavior to enable predictive caching strategies for
OLAP systems. In: DAWAK. (2000) 224–233
2. Yao, Q., An, A.: Using user access patterns for semantic query caching. In: Database and
Expert Systems Applications (DEXA). (2003)
3. Bowman, I.T., Salem, K.: Optimization of query streams using semantic prefetching. In:
Proceedings of the 2004 ACM SIGMOD, ACM Press (2004) 179–190
4. Yao, Q., An, A.: Characterizing database user’s access patterns. In: DEXA. (2004) 528–538
5. Andreas Behm, Serge Rielau, R.S.: Returning modified rows - SELECT statements with side
effects. In: VLDB 2004, Toronto, Canada. (2004)
6. Elnaffar, S., Martin, P.: Characterizing computer systems’ workloads. Tr. 2002-461, School
of Computing, Queen University. Ontario, Canada. (2002)
7. Calzarossa, M., Serazzi, G.: Workload characterization: A survey. Proc. IEEE 81 (1993)
1136–1150
8. Duy, J., Vaughan, L.: Usage data for electronic resources: A comparison between locallycollected and vendor-provided statistics. The Journal of Academic Librarianship 29 (2003)
16–22
9. Huang, X., Peng, F., An, A., Schuurmans, D.: Dynamic web log session identification with
statistical language models. Journal of the American Society for Information Science and
Technology 55 (2004) 1290 – 1303
10. Jurafsky, D., Martin, J.H.: Speech and Language Processing:An Introduction to Natural Language Processing,Computational Linguistics,and Speech Recognition. Prentice Hall (2000)
11. Jain, A.K., Murty, M.N., Flynn, P.J.: Data clustering: a review. ACM Computing Surveys 31
(1999) 264–323
12. Berkhin, P.: Survey of clustering data mining techniques. Technical report, Accrue Software,
San Jose, CA (2002)
13. Jaccard, P.: The distribution of the flora in the alpine zone. New Phytologist 11 (1912) 37–50
14. Needleman, S.B., Wunsch, C.D.: A general method applicable to the search for similarities
in the amino acid sequence of two proteins. Journal of Molecular Biology 58 (1970) 443–453
15. Guha, S., Rastogi, R., Shim, K.: ROCK: A robust clustering algorithm for categorical attributes. Information Systems 25 (2000) 345–366
16. Weinan Wang, O.R.Z.: Clustering web sessions by sequence alignment. In: 13th International
Workshop on Database and Expert Systems Applications (DEXA’02). (2002)
17. Birgit Hay, G.W., Vanhoof, K.: Clustering navigation patterns on a website using a sequence
alignment method. In: IJCAI Workshop on Intelligent Techniques for Web Personalization.
(2001)

